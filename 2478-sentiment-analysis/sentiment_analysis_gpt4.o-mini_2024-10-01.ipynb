{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e634ed-eac4-4638-8af7-115aaeb9a3b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b4df266-ed1e-45ed-8c32-d355d50b6646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_faz = pd.read_csv('data/faz_2024-11-21.csv')\n",
    "df_spiegel = pd.read_csv('data/spiegel_2024-11-21.csv')\n",
    "df_zeit = pd.read_csv('data/zeit_2024-11-21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9de1c87f-2940-41ec-938a-e5656113aa32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.OpenAI(api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6041087-9a06-4b0c-a8e7-88f5435d4be9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_sentiment_mini_formatted(text, entity, examples, model=\"gpt-4o-mini\"):\n",
    "    # JSON schema definition for structured response\n",
    "    json_schema = {\n",
    "        \"title\": \"sentiment_classification\",\n",
    "        \"description\": \"Classify the text as expressing a sentiment about the given entity.\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"sentiment\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The sentiment result, either 'positive', 'negative', or 'neutral'.\",\n",
    "            },\n",
    "            \"explanation\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The reasoning behind the sentiment classification.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"sentiment\", \"explanation\"],\n",
    "    }\n",
    "\n",
    "    # Construct the example string for the prompt\n",
    "    examples_str = \"\\n\".join([\n",
    "        f\"Example {i+1}:\\nInput:\\nText:\\n{ex['text']}\\nEntity:\\n{ex['entity']}\\nOutput:\\nsentiment: {ex['sentiment']}\\nexplanation: {ex['explanation']}\\n\"\n",
    "        for i, ex in enumerate(examples)\n",
    "    ])\n",
    "\n",
    "    # Construct the prompt to ask the model\n",
    "    prompt = f\"\"\"\n",
    "    \n",
    "    Classify the text into one of the above categories according to how the text is talking about the specified entity.\n",
    "    If the text is not talking about the entity, the sentiment is neutral.\n",
    "\n",
    "    Here are some examples to help with the classification:\n",
    "\n",
    "    {examples_str}\n",
    "\n",
    "    Now, classify the following text:\n",
    "\n",
    "    Input:\n",
    "    Text: \"{text}\"\n",
    "    Entity: \"{entity}\"\n",
    "\n",
    "    Provide the response in JSON format with the following structure:\n",
    "    {{\n",
    "        \"sentiment\": \"<positive, negative, or neutral>\",\n",
    "        \"explanation\": \"<Reasoning behind the classification>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    # Initialize the language model\n",
    "    llm = ChatOpenAI(model=model)\n",
    "\n",
    "    # Use the structured output schema\n",
    "    structured_llm = llm.with_structured_output(json_schema)\n",
    "\n",
    "    # Invoke the model with the prompt\n",
    "    response = structured_llm.invoke(prompt)\n",
    "\n",
    "    return response\n",
    "\n",
    "with open(\"examples.json\", 'r', encoding='utf-8') as file:\n",
    "    examples = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c0064ce-5a52-4840-9340-23d97dae7f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_faz['json_response_sentiment_task'] = df_faz.apply(lambda x: predict_sentiment_mini_formatted(x['content'], x['politician_name'], examples), axis=1)\n",
    "df_faz.to_csv('output/faz_sentiment_output-2024-11-21.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0edc3e4-e8f2-489a-b81b-c8a5381b0031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_spiegel['json_response_sentiment_task'] = df_spiegel.apply(lambda x: predict_sentiment_mini_formatted(x['content'], x['politician_name'], examples), axis=1)\n",
    "df_spiegel.to_csv('output/spiegel_sentiment_output-2024-11-21.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4535769-db4f-4810-92f9-a3d92cbc2a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_zeit['json_response_sentiment_task'] = df_zeit.apply(lambda x: predict_sentiment_mini_formatted(x['content'], x['politician_name'], examples), axis=1)\n",
    "df_zeit.to_csv('output/zeit_sentiment_output-2024-11-21.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
